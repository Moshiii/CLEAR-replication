{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "df_train1 = pd.read_csv('BIKER_train.QApair.csv')\n",
    "df_train1=df_train1[[\"title\",\"answer\"]]\n",
    "\n",
    "# df_train2 = pd.read_csv('Big_train.QApair.csv')\n",
    "# df_train2=df_train2[[\"title\",\"answer\"]]\n",
    "\n",
    "df_train3 = pd.read_csv('BIKER_querys_final.csv')\n",
    "df_train3=df_train3[[\"title\",\"answer\"]]\n",
    "\n",
    "# df_test = pd.read_csv(\"../BERT_sim/BIKER_1k_rdm.csv\")\n",
    "# df_test = df_test[[\"title\",\"answer\"]]\n",
    "\n",
    "# df_sim_test = pd.read_csv('../BERT_sim/Biker_1k_similar.csv')\n",
    "# df_sim_test = df_sim_test[[\"title\",\"answer\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = [df_train1,df_train3]\n",
    "df_train = pd.concat(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop_duplicates(subset=['title'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi=df_train[df_train[\"answer\"].str.contains(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10164"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10755"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(df_train[\"answer\"].to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "def generate_random_sampling_min_m_max_n(df,m=None,p=None,n=None):\n",
    "    Passage_dict = {}\n",
    "    Corpus_dict = {}\n",
    "    Answers_dict = {}\n",
    "    Triplets= []\n",
    "    api_list=[]\n",
    "    \n",
    "    gps = df.groupby(\"answer\")\n",
    "\n",
    "    for k,v in gps:\n",
    "        if len(v)>=m:\n",
    "            api_list.append(k)\n",
    "    df = df[df[\"answer\"].isin(api_list)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    print(\"len train\",len(df_train))\n",
    "    \n",
    "    gps = df.groupby(\"answer\")\n",
    "    \n",
    "    title_list = df[\"title\"].to_list()\n",
    "    answer_list = df[\"answer\"].to_list()\n",
    "    \n",
    "    print(\"len title_list\",len(title_list))\n",
    "    print(\"len answer_list\",len(answer_list))\n",
    "    \n",
    "    for idx,t in enumerate(title_list):\n",
    "        Corpus_dict[idx] = t\n",
    "        \n",
    "    for idx,t in enumerate(answer_list):\n",
    "        Answers_dict[idx] = t\n",
    "        \n",
    "    counter=0\n",
    "    \n",
    "    for idx in range(len(title_list)):\n",
    "        counter+=1\n",
    "        if counter %10000 == 0: print(counter)\n",
    "        label = Answers_dict[idx]\n",
    "        \n",
    "        gp = gps.get_group(label)\n",
    "        \n",
    "        same_api_idx_gp = list(gp.index)\n",
    "        diff_api_idx_gp = list(set(range(len(answer_list)))-set(same_api_idx_gp))\n",
    "\n",
    "        if len(same_api_idx_gp)>p:\n",
    "            same_api_idx_gp=sample(same_api_idx_gp,p)\n",
    "            \n",
    "        diff_api_idx_gp=sample(diff_api_idx_gp,n)\n",
    "\n",
    "        Passage_dict[idx] = [same_api_idx_gp,diff_api_idx_gp]\n",
    "        \n",
    "    print(\"len Corpus_dict\",len(Corpus_dict))\n",
    "    print(\"len Answers_dict\",len(Answers_dict))\n",
    "    print(\"len Passage_dict\",len(Passage_dict))\n",
    "    return df,Corpus_dict,Answers_dict,Passage_dict\n",
    "    \n",
    "def get_triplets(Passage_dict):\n",
    "    Triplets= []\n",
    "    for k, v in Passage_dict.items():\n",
    "        for x in v[0]:\n",
    "            for y in v[1]:\n",
    "                Triplets.append([k,x,y])\n",
    "    return Triplets\n",
    "\n",
    "def get_rel_doc(df,evaluate_queries, Answers_dict):\n",
    "    rel_dict ={}\n",
    "    gps = df.groupby(\"answer\")\n",
    "    \n",
    "    for q in evaluate_queries:\n",
    "        label = Answers_dict[q]\n",
    "        \n",
    "        gp = gps.get_group(label)\n",
    "        \n",
    "        same_api_idx_gp = list(gp.index)\n",
    "#         print(same_api_idx_gp)\n",
    "#         print(q)\n",
    "        same_api_idx_gp = list(set(same_api_idx_gp)-set([q]))\n",
    "\n",
    "        rel_dict[q] = [same_api_idx_gp]\n",
    "    return rel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train 34030\n",
      "len title_list 21479\n",
      "len answer_list 21479\n",
      "10000\n",
      "20000\n",
      "len Corpus_dict 21479\n",
      "len Answers_dict 21479\n",
      "len Passage_dict 21479\n"
     ]
    }
   ],
   "source": [
    "p=10\n",
    "n=10\n",
    "df_train_filtered,Corpus_dict,Answers_dict,Passage_dict = generate_random_sampling_min_m_max_n(df_train,m=5,p=p,n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n"
     ]
    }
   ],
   "source": [
    "evaluate_queries = sample(list(Passage_dict.keys()),1000)\n",
    "print(\"evaluate_queries\",len(evaluate_queries))\n",
    "evaluate_Corpus = list(set(range(len(Answers_dict)))-set(evaluate_queries))\n",
    "evaluate_rel_doc = get_rel_doc(df_train_filtered,evaluate_queries,Answers_dict)\n",
    "\n",
    "folder = \"random_dis_query\"\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder) \n",
    "data_foler = folder+\"/\"\n",
    "\n",
    "for i in range(10):\n",
    "    evaluate_queries = sample(list(Passage_dict.keys()),1000)\n",
    "    print(\"evaluate_queries\",len(evaluate_queries))\n",
    "    evaluate_Corpus = list(set(range(len(Answers_dict)))-set(evaluate_queries))\n",
    "    evaluate_rel_doc = get_rel_doc(df_train_filtered,evaluate_queries,Answers_dict)\n",
    "    with open(data_foler+'evaluate_queries'+str(i)+'.json', 'w') as jsonfile:\n",
    "        json.dump(evaluate_queries, jsonfile)\n",
    "\n",
    "    with open(data_foler+'evaluate_Corpus'+str(i)+'.json', 'w') as jsonfile:\n",
    "        json.dump(evaluate_Corpus, jsonfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train 34030\n",
      "len title_list 1991\n",
      "len answer_list 1991\n",
      "len Corpus_dict 1991\n",
      "len Answers_dict 1991\n",
      "len Passage_dict 1991\n"
     ]
    }
   ],
   "source": [
    "p=10\n",
    "n=10\n",
    "df_train_filtered_multi,Corpus_dict_multi,Answers_dict_multi,Passage_dict_multi = generate_random_sampling_min_m_max_n(df_multi,m=5,p=p,n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n",
      "evaluate_queries 1000\n"
     ]
    }
   ],
   "source": [
    "evaluate_multi_queries = sample(list(Passage_dict_multi.keys()),1000)\n",
    "print(\"evaluate_queries\",len(evaluate_multi_queries))\n",
    "evaluate_multi_Corpus = list(set(range(len(Answers_dict_multi)))-set(evaluate_multi_queries))\n",
    "evaluate_multi_rel_doc = get_rel_doc(df_train_filtered_multi,evaluate_multi_queries,Answers_dict_multi)\n",
    "\n",
    "folder = \"random_dis_query_multi\"\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder) \n",
    "data_foler = folder+\"/\"\n",
    "\n",
    "for i in range(10):\n",
    "    evaluate_multi_queries = sample(list(Passage_dict_multi.keys()),1000)\n",
    "    print(\"evaluate_queries\",len(evaluate_multi_queries))\n",
    "    evaluate_multi_Corpus = list(set(range(len(Answers_dict_multi)))-set(evaluate_multi_queries))\n",
    "    evaluate_multi_rel_doc = get_rel_doc(df_train_filtered_multi,evaluate_multi_queries,Answers_dict_multi)\n",
    "    \n",
    "    with open(data_foler+'evaluate_queries'+str(i)+'.json', 'w') as jsonfile:\n",
    "        json.dump(evaluate_multi_queries, jsonfile)\n",
    "\n",
    "    with open(data_foler+'evaluate_Corpus'+str(i)+'.json', 'w') as jsonfile:\n",
    "        json.dump(evaluate_multi_Corpus, jsonfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_biker_test = []\n",
    "for index, row in df_train3.iterrows():\n",
    "    y = str(list(eval(row['answer'])))\n",
    "    if y in Answers_dict.values():\n",
    "        filtered_biker_test.append((row['title'],y))\n",
    "len(filtered_biker_test)\n",
    "df_filtered_biker_test = pd.DataFrame(data = filtered_biker_test,columns=[\"title\",\"answer\"])\n",
    "df_filtered_biker_test.to_csv(\"Biker_test_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train 34030\n",
      "len title_list 1046\n",
      "len answer_list 1046\n",
      "len Corpus_dict 1046\n",
      "len Answers_dict 1046\n",
      "len Passage_dict 1046\n",
      "evaluate_queries 250\n",
      "triplets 93360\n",
      "gps 85\n",
      "len train 34030\n",
      "len title_list 1007\n",
      "len answer_list 1007\n",
      "len Corpus_dict 1007\n",
      "len Answers_dict 1007\n",
      "len Passage_dict 1007\n",
      "evaluate_queries 250\n",
      "triplets 88090\n",
      "gps 90\n",
      "len train 34030\n",
      "len title_list 957\n",
      "len answer_list 957\n",
      "len Corpus_dict 957\n",
      "len Answers_dict 957\n",
      "len Passage_dict 957\n",
      "evaluate_queries 250\n",
      "triplets 82950\n",
      "gps 87\n",
      "len train 34030\n",
      "len title_list 1083\n",
      "len answer_list 1083\n",
      "len Corpus_dict 1083\n",
      "len Answers_dict 1083\n",
      "len Passage_dict 1083\n",
      "evaluate_queries 250\n",
      "triplets 96410\n",
      "gps 90\n",
      "len train 34030\n",
      "len title_list 1060\n",
      "len answer_list 1060\n",
      "len Corpus_dict 1060\n",
      "len Answers_dict 1060\n",
      "len Passage_dict 1060\n",
      "evaluate_queries 250\n",
      "triplets 92550\n",
      "gps 93\n",
      "len train 34030\n",
      "len title_list 1087\n",
      "len answer_list 1087\n",
      "len Corpus_dict 1087\n",
      "len Answers_dict 1087\n",
      "len Passage_dict 1087\n",
      "evaluate_queries 250\n",
      "triplets 93160\n",
      "gps 98\n",
      "len train 34030\n",
      "len title_list 1061\n",
      "len answer_list 1061\n",
      "len Corpus_dict 1061\n",
      "len Answers_dict 1061\n",
      "len Passage_dict 1061\n",
      "evaluate_queries 250\n",
      "triplets 94540\n",
      "gps 89\n",
      "len train 34030\n",
      "len title_list 1034\n",
      "len answer_list 1034\n",
      "len Corpus_dict 1034\n",
      "len Answers_dict 1034\n",
      "len Passage_dict 1034\n",
      "evaluate_queries 250\n",
      "triplets 91480\n",
      "gps 89\n",
      "len train 34030\n",
      "len title_list 1049\n",
      "len answer_list 1049\n",
      "len Corpus_dict 1049\n",
      "len Answers_dict 1049\n",
      "len Passage_dict 1049\n",
      "evaluate_queries 250\n",
      "triplets 93170\n",
      "gps 86\n",
      "len train 34030\n",
      "len title_list 1030\n",
      "len answer_list 1030\n",
      "len Corpus_dict 1030\n",
      "len Answers_dict 1030\n",
      "len Passage_dict 1030\n",
      "evaluate_queries 250\n",
      "triplets 91480\n",
      "gps 85\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# for p in [1,3,5,10,15]:\n",
    "#     for n in [1,3,5,10,15]:\n",
    "        \n",
    "for i in range(10):\n",
    "    df_train1= df_train.sample(n=3000)\n",
    "    p=10\n",
    "    n=10\n",
    "\n",
    "    df_train_filtered,Corpus_dict,Answers_dict,Passage_dict = generate_random_sampling_min_m_max_n(df_train1,m=5,p=p,n=n)\n",
    "\n",
    "    evaluate_queries = sample(list(Passage_dict.keys()),250)\n",
    "    print(\"evaluate_queries\",len(evaluate_queries))\n",
    "    evaluate_Corpus = list(set(range(len(Answers_dict)))-set(evaluate_queries))\n",
    "    evaluate_rel_doc = get_rel_doc(df_train_filtered,evaluate_queries,Answers_dict)\n",
    "\n",
    "    test_queries = sample(list(Passage_dict.keys()),250)\n",
    "    test_Corpus = list(set(range(len(Answers_dict)))-set(evaluate_queries))\n",
    "    test_rel_doc = get_rel_doc(df_train_filtered,evaluate_queries,Answers_dict)\n",
    "\n",
    "    triplets = get_triplets(Passage_dict)\n",
    "    print(\"triplets\",len(triplets))\n",
    "\n",
    "    gps = df_train_filtered.groupby(\"answer\")\n",
    "    print(\"gps\",len(gps))\n",
    "\n",
    "    \n",
    "    folder = \"random_dis_3k_min_5_max_\"+str(p)+\"_ir_\"+str(n)+\"_\"+str(i)\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder) \n",
    "    data_foler = folder+\"/\"\n",
    "    with open(data_foler+'Corpus_dict.json', 'w') as jsonfile:\n",
    "        json.dump(Corpus_dict, jsonfile)\n",
    "\n",
    "    with open(data_foler+'Answers_dict.json', 'w') as jsonfile:\n",
    "        json.dump(Answers_dict, jsonfile)\n",
    "\n",
    "    with open(data_foler+'Passage_dict.json', 'w') as jsonfile:\n",
    "        json.dump(Passage_dict, jsonfile)\n",
    "\n",
    "\n",
    "    with open(data_foler+'evaluate_queries.json', 'w') as jsonfile:\n",
    "        json.dump(evaluate_queries, jsonfile)\n",
    "\n",
    "    with open(data_foler+'evaluate_Corpus.json', 'w') as jsonfile:\n",
    "        json.dump(evaluate_Corpus, jsonfile)\n",
    "\n",
    "    with open(data_foler+'evaluate_rel_doc.json', 'w') as jsonfile:\n",
    "        json.dump(evaluate_rel_doc, jsonfile)\n",
    "\n",
    "\n",
    "    with open(data_foler+'test_queries.json', 'w') as jsonfile:\n",
    "        json.dump(test_queries, jsonfile)\n",
    "\n",
    "    with open(data_foler+'test_Corpus.json', 'w') as jsonfile:\n",
    "        json.dump(test_Corpus, jsonfile)\n",
    "\n",
    "    with open(data_foler+'test_rel_doc.json', 'w') as jsonfile:\n",
    "        json.dump(test_rel_doc, jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_multi_queries = sample(list(Passage_dict_multi.keys()),1000)\n",
    "# print(\"evaluate_queries\",len(evaluate_multi_queries))\n",
    "# evaluate_multi_Corpus = list(set(range(len(Answers_dict_multi)))-set(evaluate_multi_queries))\n",
    "# evaluate_multi_rel_doc = get_rel_doc(df_train_filtered_multi,evaluate_multi_queries,Answers_dict_multi)\n",
    "\n",
    "data_folder = '../@SentenceBert_finetune/full_data_min_5_max_10_ir_10/'\n",
    "with open(data_folder+'evaluate_multi_queries.json', 'w') as jsonfile:\n",
    "    json.dump(evaluate_multi_queries, jsonfile)\n",
    "\n",
    "with open(data_folder+'evaluate_multi_Corpus.json', 'w') as jsonfile:\n",
    "    json.dump(evaluate_multi_Corpus, jsonfile)\n",
    "\n",
    "with open(data_folder+'evaluate_multi_rel_doc.json', 'w') as jsonfile:\n",
    "    json.dump(evaluate_multi_rel_doc, jsonfile)\n",
    "    \n",
    "\n",
    "\n",
    "test_corpus = []\n",
    "test_answers = []\n",
    "collection_filepath = os.path.join(data_folder, 'evaluate_multi_Corpus.json')\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "    for k in data:\n",
    "        test_corpus.append(corpus[k])\n",
    "        test_answers.append(Answers[k])\n",
    "\n",
    "test_queries = []\n",
    "test_queries_answers = []\n",
    "collection_filepath = os.path.join(data_folder, 'evaluate_multi_queries.json')\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "    for k in data:\n",
    "        test_queries.append(corpus[k])\n",
    "        test_queries_answers.append(Answers[k])\n",
    "        \n",
    "        \n",
    "df1 = pd.DataFrame(data = list(zip(test_corpus,test_answers)),columns=[\"title\",\"answer\"])\n",
    "df1.to_csv(\"test_corpus_multi_min_5_max_10_ir_10.csv\")\n",
    "\n",
    "df2 = pd.DataFrame(data = list(zip(test_queries,test_queries_answers)),columns=[\"title\",\"answer\"])\n",
    "df2.to_csv(\"test_queries_multi_min_5_max_10_ir_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we read the MS Marco dataset\n",
    "import os\n",
    "data_folder = '../@SentenceBert_finetune/full_data_min_5_max_10_ir_10/'\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "# in the order of 1 to 30k\n",
    "corpus = []\n",
    "collection_filepath = os.path.join(data_folder, 'Corpus_dict.json')\n",
    "#\"evaluate_Corpus_min_2_max_10.json\"\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "    for k in range(len(data)):\n",
    "        corpus.append(data[str(k)])\n",
    "\n",
    "# in the order of 1 to 30k\n",
    "Answers = []\n",
    "collection_filepath = os.path.join(data_folder, 'Answers_dict.json')\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "    for k in range(len(data)):\n",
    "        Answers.append(data[str(k)])\n",
    "\n",
    "\n",
    "evaluate_corpus = []\n",
    "evaluate_answers = []\n",
    "collection_filepath = os.path.join(data_folder, 'evaluate_Corpus.json')\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "    for k in data:\n",
    "        evaluate_corpus.append(corpus[k])\n",
    "        evaluate_answers.append(Answers[k])\n",
    "\n",
    "queries = []\n",
    "queries_answers = []\n",
    "collection_filepath = os.path.join(data_folder, 'evaluate_queries.json')\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "    for k in data:\n",
    "        queries.append(corpus[k])\n",
    "        queries_answers.append(Answers[k])\n",
    "        \n",
    "test_corpus = []\n",
    "test_answers = []\n",
    "collection_filepath = os.path.join(data_folder, 'test_Corpus.json')\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "    for k in data:\n",
    "        test_corpus.append(corpus[k])\n",
    "        test_answers.append(Answers[k])\n",
    "\n",
    "test_queries = []\n",
    "test_queries_answers = []\n",
    "collection_filepath = os.path.join(data_folder, 'test_queries.json')\n",
    "with open(collection_filepath, 'r', encoding='utf8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "    for k in data:\n",
    "        test_queries.append(corpus[k])\n",
    "        test_queries_answers.append(Answers[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_so_test = pd.read_csv(\"SO_test_latest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I resize an image from a URL into a JP...</td>\n",
       "      <td>['javax.swing.ImageIcon.getImage']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>array with random ints but no duplicates and f...</td>\n",
       "      <td>['java.util.Random.nextInt', 'java.util.stream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to execute multiple SQL queries defined in...</td>\n",
       "      <td>['java.lang.String.split', 'java.nio.file.File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StructField issue at compilation when specifyi...</td>\n",
       "      <td>['java.util.Arrays.asList']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jsoup combine multiple Evaluator</td>\n",
       "      <td>['java.lang.String.join']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>How to conver date on arguments into format da...</td>\n",
       "      <td>['java.text.SimpleDateFormat.parse', 'java.tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>\"BufferedReader\" vs. \"java.io.BufferedReader\"....</td>\n",
       "      <td>['java.io.BufferedReader.readLine']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>How to hide the warning \"This type of file can...</td>\n",
       "      <td>['java.lang.System.setProperty']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Some way to get files CRC from file system?</td>\n",
       "      <td>['java.util.zip.Checksum.update', 'java.util.z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Is it possible to dump the bytecode instrument...</td>\n",
       "      <td>['java.io.StringWriter.toString']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    How can I resize an image from a URL into a JP...   \n",
       "1    array with random ints but no duplicates and f...   \n",
       "2    How to execute multiple SQL queries defined in...   \n",
       "3    StructField issue at compilation when specifyi...   \n",
       "4                     Jsoup combine multiple Evaluator   \n",
       "..                                                 ...   \n",
       "594  How to conver date on arguments into format da...   \n",
       "595  \"BufferedReader\" vs. \"java.io.BufferedReader\"....   \n",
       "596  How to hide the warning \"This type of file can...   \n",
       "597        Some way to get files CRC from file system?   \n",
       "598  Is it possible to dump the bytecode instrument...   \n",
       "\n",
       "                                                answer  \n",
       "0                   ['javax.swing.ImageIcon.getImage']  \n",
       "1    ['java.util.Random.nextInt', 'java.util.stream...  \n",
       "2    ['java.lang.String.split', 'java.nio.file.File...  \n",
       "3                          ['java.util.Arrays.asList']  \n",
       "4                            ['java.lang.String.join']  \n",
       "..                                                 ...  \n",
       "594  ['java.text.SimpleDateFormat.parse', 'java.tex...  \n",
       "595                ['java.io.BufferedReader.readLine']  \n",
       "596                   ['java.lang.System.setProperty']  \n",
       "597  ['java.util.zip.Checksum.update', 'java.util.z...  \n",
       "598                  ['java.io.StringWriter.toString']  \n",
       "\n",
       "[599 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_so_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_so_test = []\n",
    "for index, row in df_so_test.iterrows():\n",
    "    y = str(list(eval(row['answer'])))\n",
    "    if y in Answers:\n",
    "        filtered_so_test.append((row['title'],y))\n",
    "len(filtered_so_test)\n",
    "filtered_so_test = pd.DataFrame(data = filtered_so_test,columns=[\"title\",\"answer\"])\n",
    "# filtered_so_test.to_csv(\"Biker_test_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StructField issue at compilation when specifyi...</td>\n",
       "      <td>['java.util.Arrays.asList']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jsoup combine multiple Evaluator</td>\n",
       "      <td>['java.lang.String.join']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Update class variables on button click</td>\n",
       "      <td>['java.lang.Integer.valueOf']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Changing colour of all buttons in netbeans</td>\n",
       "      <td>['java.lang.String.valueOf']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SQLite database update doesn't update</td>\n",
       "      <td>['java.lang.String.valueOf']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Java - Converting character of string to upper...</td>\n",
       "      <td>['java.util.regex.Pattern.compile']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Will methods in lambda only be evaluated when ...</td>\n",
       "      <td>['java.lang.Runnable.run']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>How do i fix a non static method being called ...</td>\n",
       "      <td>['java.util.Scanner.next']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>\"BufferedReader\" vs. \"java.io.BufferedReader\"....</td>\n",
       "      <td>['java.io.BufferedReader.readLine']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>How to hide the warning \"This type of file can...</td>\n",
       "      <td>['java.lang.System.setProperty']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    StructField issue at compilation when specifyi...   \n",
       "1                     Jsoup combine multiple Evaluator   \n",
       "2               Update class variables on button click   \n",
       "3           Changing colour of all buttons in netbeans   \n",
       "4                SQLite database update doesn't update   \n",
       "..                                                 ...   \n",
       "222  Java - Converting character of string to upper...   \n",
       "223  Will methods in lambda only be evaluated when ...   \n",
       "224  How do i fix a non static method being called ...   \n",
       "225  \"BufferedReader\" vs. \"java.io.BufferedReader\"....   \n",
       "226  How to hide the warning \"This type of file can...   \n",
       "\n",
       "                                  answer  \n",
       "0            ['java.util.Arrays.asList']  \n",
       "1              ['java.lang.String.join']  \n",
       "2          ['java.lang.Integer.valueOf']  \n",
       "3           ['java.lang.String.valueOf']  \n",
       "4           ['java.lang.String.valueOf']  \n",
       "..                                   ...  \n",
       "222  ['java.util.regex.Pattern.compile']  \n",
       "223           ['java.lang.Runnable.run']  \n",
       "224           ['java.util.Scanner.next']  \n",
       "225  ['java.io.BufferedReader.readLine']  \n",
       "226     ['java.lang.System.setProperty']  \n",
       "\n",
       "[227 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_so_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_so_test.to_csv(\"SO_test_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21479\n",
      "20479\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus))\n",
    "print(len(evaluate_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(Answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter=0\n",
    "list_=[]\n",
    "for l in Answers:\n",
    "    if \",\" in l:\n",
    "        list_.append(l)\n",
    "        counter +=1\n",
    "print(counter)\n",
    "\n",
    "len(list(set(list_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data = list(zip(test_corpus,test_answers)),columns=[\"title\",\"answer\"])\n",
    "df1.to_csv(\"test_corpus_min_5_max_10_ir_10.csv\")\n",
    "\n",
    "df2 = pd.DataFrame(data = list(zip(test_queries,test_queries_answers)),columns=[\"title\",\"answer\"])\n",
    "df2.to_csv(\"test_queries_min_5_max_10_ir_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
