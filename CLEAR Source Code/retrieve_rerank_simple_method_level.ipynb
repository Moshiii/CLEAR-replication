{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"retrieve_rerank_simple_method_level.ipynb","provenance":[{"file_id":"1enoJ5vRbCduXPMhCdHnJiZOQaqgJHvDO","timestamp":1613920255590},{"file_id":"1l6stpYdRMmeDBK_vw0L5NitdiAuhdsAr","timestamp":1613879909130}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b6c16ed2a92742d08e82b4121abad0f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_60cb711ea76646409e4b83f68f7500c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c444c9ed6344cceab704d3b4a5a74a1","IPY_MODEL_3a087a13fdf240d7a357eaf0ea1beb4c"]}},"60cb711ea76646409e4b83f68f7500c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c444c9ed6344cceab704d3b4a5a74a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dcd67dde6d444a1f81d2bfd37c42976e","_dom_classes":[],"description":"Batches: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":611,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":611,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a5daa5fd88494bfe891848da78fbe5ed"}},"3a087a13fdf240d7a357eaf0ea1beb4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7922b4c0e3614336ac6b854bb6696db8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 611/611 [00:07&lt;00:00, 81.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b895cd9eef044312a1f18bf364e0fc91"}},"dcd67dde6d444a1f81d2bfd37c42976e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a5daa5fd88494bfe891848da78fbe5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7922b4c0e3614336ac6b854bb6696db8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b895cd9eef044312a1f18bf364e0fc91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7b6db60bbd34930a06cae5c32f69c39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5e9ea997fd564967b25a2f3c4f22cf38","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_badf556fdd864bd7b3ab2d99bf9194b6","IPY_MODEL_85cc9e2e82be4dd6840889223a9ab366"]}},"5e9ea997fd564967b25a2f3c4f22cf38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"badf556fdd864bd7b3ab2d99bf9194b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e261d54e81e24d1e85eb70f4473c0f05","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":19532,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":19532,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e767fefc0000469db1d668d1fbd771dd"}},"85cc9e2e82be4dd6840889223a9ab366":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_64f61c03259f41cea9ecbbc862b56f00","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 19532/19532 [00:00&lt;00:00, 80885.31it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2fc76fec488947978f4b9d547e4b774f"}},"e261d54e81e24d1e85eb70f4473c0f05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e767fefc0000469db1d668d1fbd771dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64f61c03259f41cea9ecbbc862b56f00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2fc76fec488947978f4b9d547e4b774f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZyP3dXRfcXLa"},"source":["# Question-Answering using Simple Wikipedia Index\n","\n","This examples demonstrates the setup for Query / Question-Answer-Retrieval.\n","\n","You can input a query or a question. The script then uses semantic search\n","to find relevant passages in Simple English Wikipedia (as it is smaller and fits better in RAM).\n","\n","For semantic search, we use SentenceTransformer('msmarco-distilbert-base-v2') and retrieve\n","100 potentially passages that answer the input query.\n","\n","Next, we use a more powerful CrossEncoder (cross_encoder = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6')) that\n","scores the query and all retrieved passages for their relevancy. The cross-encoder is neccessary to filter out certain noise\n","that might be retrieved from the semantic search step.\n"]},{"cell_type":"code","metadata":{"id":"-bQVJvVMP1BV"},"source":["# !df -h\n","# !cat /proc/cpuinfo\n","# !cat /proc/meminfo"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2R9TjVzNV_E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619185469319,"user_tz":240,"elapsed":10161,"user":{"displayName":"moshi wei","photoUrl":"","userId":"12764116733203618955"}},"outputId":"17c2d494-f975-4f8f-b181-c6e4526c2acd"},"source":["!pip install -U sentence-transformers rank_bm25"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentence-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/87/49dc49e13ac107ce912c2f3f3fd92252c6d4221e88d1e6c16747044a11d8/sentence-transformers-1.1.0.tar.gz (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 6.0MB/s \n","\u001b[?25hCollecting rank_bm25\n","  Downloading https://files.pythonhosted.org/packages/16/5a/23ed3132063a0684ea66fb410260c71c4ffda3b99f8f1c021d1e245401b5/rank_bm25-0.2.1-py3-none-any.whl\n","Collecting transformers<5.0.0,>=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 18.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 42.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 28.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 42.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-1.1.0-cp37-none-any.whl size=119615 sha256=ad5d33102a7bdda13369d90511ca55e67b9ffca6762bc4b4ce02de6ebc792b26\n","  Stored in directory: /root/.cache/pip/wheels/84/cb/21/1066bff3027215c760ca14a198f698bca8fccb92e33e2327eb\n","Successfully built sentence-transformers\n","Installing collected packages: sacremoses, tokenizers, transformers, sentencepiece, sentence-transformers, rank-bm25\n","Successfully installed rank-bm25-0.2.1 sacremoses-0.0.45 sentence-transformers-1.1.0 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MNILt5hP4e0U"},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0t5ZZGHK3jf"},"source":["import json\n","from sentence_transformers import SentenceTransformer, CrossEncoder, util\n","import time\n","import gzip\n","import os\n","import torch\n","\n","if not torch.cuda.is_available():\n","  print(\"Warning: No GPU found. Please add GPU to your notebook\")\n","\n","\n","#We use the Bi-Encoder to encode all passages, so that we can use it with sematic search\n","model_name = 'msmarco-distilbert-base-v2'\n","\n","# model_name = \"/content/drive/MyDrive/SBRT_output/training_biker_distilroberta_base_bi-encoder-min_50distilroberta-base-2021-02-23_02-33-56\"\n","# model_name = \"/content/drive/MyDrive/SBRT_output/training_biker_bi-encoder-min_5_max_10_ir_10_distilroberta-base_3_iter\"\n","# model_name = \"/content/drive/MyDrive/SBRT_output/training_biker_bi-encoder-min_5_max_10_ir_10_distilroberta-base-full-best\"\n","bi_encoder = SentenceTransformer(model_name)\n","top_k = 100     #Number of passages we want to retrieve with the bi-encoder\n","\n","#The bi-encoder will retrieve 100 documents. We use a cross-encoder, to re-rank the results list to improve the quality\n","cross_encoder = CrossEncoder('/content/drive/MyDrive/SBRT_output/training_biker_cross-encoder-30_iter_TinyBERT-full-best')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8SXjFqSbE33"},"source":["### Now we read the MS Marco dataset\n","data_folder = '/content/drive/MyDrive/biker_data/min_5_max_10_ir_10_30k'\n","\n","os.makedirs(data_folder, exist_ok=True)\n","import json \n","\n","# in the order of 1 to 30k\n","corpus = []\n","collection_filepath = os.path.join(data_folder, 'Corpus_dict.json')\n","#\"evaluate_Corpus_min_2_max_10.json\"\n","with open(collection_filepath, 'r', encoding='utf8') as fIn:\n","  data = json.load(fIn)\n","  for k in range(len(data)):\n","    corpus.append(data[str(k)])\n","\n","# in the order of 1 to 30k\n","Answers = []\n","collection_filepath = os.path.join(data_folder, 'Answers_dict.json')\n","with open(collection_filepath, 'r', encoding='utf8') as fIn:\n","  data = json.load(fIn)\n","  for k in range(len(data)):\n","    Answers.append(data[str(k)])\n","\n","\n","evaluate_corpus = []\n","evaluate_answers = []\n","collection_filepath = os.path.join(data_folder, 'evaluate_Corpus.json')\n","with open(collection_filepath, 'r', encoding='utf8') as fIn:\n","  data = json.load(fIn)\n","  for k in data:\n","    evaluate_corpus.append(corpus[k])\n","    evaluate_answers.append(Answers[k])\n","\n","queries = []\n","queries_answers = []\n","collection_filepath = os.path.join(data_folder, 'evaluate_multi_queries.json')\n","with open(collection_filepath, 'r', encoding='utf8') as fIn:\n","  data = json.load(fIn)\n","  for k in data:\n","    queries.append(corpus[k])\n","    queries_answers.append(Answers[k])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DtH9XQ4t-w4o"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNb1ZFfktNP-"},"source":["# df_test= pd.read_csv(\"/content/drive/MyDrive/biker_data/min_5_max_10_ir_10_30k/Biker_test_filtered.csv\")\n","# # df_test= pd.read_csv(\"/content/drive/MyDrive/biker_data/min_5_max_10_ir_10_30k/SO_test_filtered.csv\")\n","# queries = df_test[\"title\"].to_list()\n","# queries_answers = df_test[\"answer\"].to_list()\n","# queries_answers=[str(list(eval(x))) for x in queries_answers]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fs1l2oJyLb_","executionInfo":{"status":"ok","timestamp":1618707145673,"user_tz":240,"elapsed":39090,"user":{"displayName":"moshi wei","photoUrl":"","userId":"12764116733203618955"}},"outputId":"3130ce4d-e6ae-458e-bb30-7100087ab2e8"},"source":["len(queries)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZi1bwKztVkm","executionInfo":{"status":"ok","timestamp":1618707145674,"user_tz":240,"elapsed":37841,"user":{"displayName":"moshi wei","photoUrl":"","userId":"12764116733203618955"}},"outputId":"8c35c188-49cf-4f42-d8cc-1a50569c31fb"},"source":["queries[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Sorting custom class array-list string using Collections.sort',\n"," 'String IdentityHashMap vs HashMap performance',\n"," 'Thread.sleep() VS Executor.scheduleWithFixedDelay()',\n"," 'Number of subfolders in a folder directory',\n"," 'How to test whether a char is NOT in a string? (java, junit)',\n"," 'String.format option for locale specific double formatting like Double.toString()?',\n"," 'Is there a way to know if a Java program was started from the command line or from a jar file?',\n"," 'How to escape special characters in the regex ***(.*)',\n"," 'GWT interaction with external standalone application',\n"," 'Java Collection compare generic class that extends interface that extends comparable']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"cKtZIBcX3a_8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618707146032,"user_tz":240,"elapsed":36619,"user":{"displayName":"moshi wei","photoUrl":"","userId":"12764116733203618955"}},"outputId":"6ef7e18b-6949-4cfc-c661-9a36015182f0"},"source":["# df= pd.read_csv(\"/content/drive/MyDrive/biker_data/min_5_max_10_ir_10_30k/Big_train.QApair.csv\")\n","\n","filtered_evaluate_corpus =[]\n","filtered_evaluate_answers =[]\n","print(len(evaluate_corpus))\n","print(len(evaluate_answers))\n","for idx,q in enumerate(evaluate_corpus):\n","  if not q in queries:\n","    filtered_evaluate_corpus.append(evaluate_corpus[idx])\n","    filtered_evaluate_answers.append(evaluate_answers[idx])\n","evaluate_corpus = filtered_evaluate_corpus\n","evaluate_answers = filtered_evaluate_answers\n","print(len(evaluate_corpus))\n","print(len(evaluate_answers))\n","#   queries_answers[idx] = str(list(eval(queries_answers[idx])))\n","#   df=df[~(df[\"title\"].isin(queries))]\n","# evaluate_corpus=df[\"title\"].to_list()\n","# evaluate_answers=df[\"answer\"].to_list()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20481\n","20481\n","19532\n","19532\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Djeht8GCn_Z8","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["b6c16ed2a92742d08e82b4121abad0f3","60cb711ea76646409e4b83f68f7500c7","9c444c9ed6344cceab704d3b4a5a74a1","3a087a13fdf240d7a357eaf0ea1beb4c","dcd67dde6d444a1f81d2bfd37c42976e","a5daa5fd88494bfe891848da78fbe5ed","7922b4c0e3614336ac6b854bb6696db8","b895cd9eef044312a1f18bf364e0fc91"]},"executionInfo":{"status":"ok","timestamp":1618707159173,"user_tz":240,"elapsed":47534,"user":{"displayName":"moshi wei","photoUrl":"","userId":"12764116733203618955"}},"outputId":"f40e8eaf-72ab-4af0-c638-5f7377b21b62"},"source":["passages = evaluate_corpus\n","# passages = corpus\n","corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)\n","# passages = evaluate_corpus\n","# passages = corpus"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6c16ed2a92742d08e82b4121abad0f3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Batches', max=611.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["e7b6db60bbd34930a06cae5c32f69c39","5e9ea997fd564967b25a2f3c4f22cf38","badf556fdd864bd7b3ab2d99bf9194b6","85cc9e2e82be4dd6840889223a9ab366","e261d54e81e24d1e85eb70f4473c0f05","e767fefc0000469db1d668d1fbd771dd","64f61c03259f41cea9ecbbc862b56f00","2fc76fec488947978f4b9d547e4b774f"]},"id":"0rueR6ovrs01","executionInfo":{"status":"ok","timestamp":1618707159532,"user_tz":240,"elapsed":44693,"user":{"displayName":"moshi wei","photoUrl":"","userId":"12764116733203618955"}},"outputId":"bade67c9-77dc-4755-cecb-82bc3e25d874"},"source":["# We also compare the results to lexical search (keyword search). Here, we use \n","# the BM25 algorithm which is implemented in the rank_bm25 package.\n","\n","from rank_bm25 import BM25Okapi\n","from sklearn.feature_extraction import stop_words\n","import string\n","from tqdm.autonotebook import tqdm\n","import numpy as np\n","\n","# We lower case our text and remove stop-words from indexing\n","def bm25_tokenizer(text):\n","  tokenized_doc = []\n","  for token in text.lower().split():\n","    token = token.strip(string.punctuation)\n","\n","    if len(token) > 0 and token not in stop_words.ENGLISH_STOP_WORDS:\n","      tokenized_doc.append(token)\n","  return tokenized_doc\n","\n","tokenized_corpus = []\n","for passage in tqdm(passages):\n","  tokenized_corpus.append(bm25_tokenizer(passage))\n","\n","bm25 = BM25Okapi(tokenized_corpus)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7b6db60bbd34930a06cae5c32f69c39","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=19532.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tegs4vah3ViH"},"source":["#This function will search all wikipedia articles for passages that\n","#answer the query\n","def evaluate(query,answer):\n","\n","\n","  top_k=50\n","  answer=eval(answer)\n","  print(query, answer)\n","\n","  bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n","  top_n = np.argpartition(bm25_scores, -50)[-50:]\n","  bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n","  bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n","\n","  BM25_counter = -1 \n","  BM25_tmp_map = 0\n","  BM25_tmp_mrr = 0\n","  temp_hits = 0\n","  tmep_answer = answer[:]\n","  for idx, hit in enumerate(bm25_hits[0:50]):\n","      candidate = eval(evaluate_answers[hit['corpus_id']].replace(\"\\n\", \" \"))\n","      for c in candidate:\n","        if c in tmep_answer:\n","          if BM25_counter == -1: BM25_counter = idx + 1\n","          temp_hits+=1\n","          \n","          BM25_tmp_map += temp_hits/(idx+1)\n","          tmep_answer.remove(c)\n","\n","  # print(temp_hits)\n","  # print(BM25_tmp_map)\n","  BM25_tmp_map /= len(answer)\n","  BM25_tmp_mrr = 0.0\n","  if BM25_counter!= -1:\n","    BM25_tmp_mrr = 1/BM25_counter\n","\n","\n","\n","  question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n","  Encoder_hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n","  Encoder_hits = Encoder_hits[0]  # Get the hits for the first query\n","\n","  cross_inp = [[query, passages[hit['corpus_id']]] for hit in Encoder_hits]\n","  cross_scores = cross_encoder.predict(cross_inp)\n","  for idx in range(len(cross_scores)):\n","      Encoder_hits[idx]['cross-score'] = cross_scores[idx]\n","\n","  \n","  Bi_Encoder_counter = -1 \n","  Bi_Encoder_tmp_map = 0\n","  Bi_Encoder_tmp_mrr = 0\n","\n","  Bi_Encoder_hit_list=[0]*top_k\n","  Bi_Encoder_hit_recall_list=[0]*top_k\n","\n","  temp_hits = 0\n","  Encoder_hits = sorted(Encoder_hits, key=lambda x: x['score'], reverse=True) \n","  tmep_answer = answer[:]\n","  for idx,hit in enumerate(Encoder_hits[0:top_k]):\n","      candidate= eval(evaluate_answers[hit['corpus_id']].replace(\"\\n\", \" \"))\n","      for c in candidate:\n","\n","        if c in answer:\n","          if not query==passages[hit['corpus_id']].replace(\"\\n\", \" \").replace(\"?\",\"\"):\n","            Bi_Encoder_hit_list[idx]=1\n","\n","        if c in tmep_answer:\n","          if not query==passages[hit['corpus_id']].replace(\"\\n\", \" \").replace(\"?\",\"\"):\n","            \n","\n","            if Bi_Encoder_counter == -1: \n","              Bi_Encoder_counter = idx + 1\n","\n","              \n","              print(\"\\t{:.3f}\\t{}\\t{}\".format(hit['score'], passages[hit['corpus_id']].replace(\"\\n\", \" \"), evaluate_answers[hit['corpus_id']].replace(\"\\n\", \" \")))\n","            temp_hits+=1\n","\n","\n","            Bi_Encoder_hit_recall_list[idx]=1\n","\n","\n","            Bi_Encoder_tmp_map += temp_hits/(idx+1)\n","            tmep_answer.remove(c)\n","  Bi_Encoder_tmp_map /= len(answer)\n","  Bi_Encoder_tmp_mrr = 0.0\n","  if Bi_Encoder_counter!= -1:\n","    Bi_Encoder_tmp_mrr = 1/Bi_Encoder_counter\n","\n","  # answer_api= Answers[hit['corpus_id']]\n","  Cross_Encoder_counter = -1 \n","  Cross_Encoder_tmp_map = 0\n","  Cross_Encoder_tmp_mrr = 0\n","\n","  Cross_Encoder_hit_list=[0]*top_k\n","  Cross_Encoder_hit_recall_list=[0]*top_k\n","\n","  temp_hits = 0\n","  Encoder_hits = sorted(Encoder_hits, key=lambda x: x['cross-score'], reverse=True)\n","  tmep_answer = answer[:]\n","  for idx,hit in enumerate(Encoder_hits[0:50]):\n","      # print(\"\\t{:.3f}\\t{}\\t{}\".format(hit['cross-score'], passages[hit['corpus_id']].replace(\"\\n\", \" \"), Answers[hit['corpus_id']].replace(\"\\n\", \" \")))\n","      candidate= eval(evaluate_answers[hit['corpus_id']].replace(\"\\n\", \" \"))\n","      # print(candidate,answer)\n","      for c in candidate:\n","\n","        if c in answer:\n","          if not query==passages[hit['corpus_id']].replace(\"\\n\", \" \").replace(\"?\",\"\"):\n","            Cross_Encoder_hit_list[idx]=1\n","\n","        if c in tmep_answer:\n","\n","          if Cross_Encoder_counter == -1: Cross_Encoder_counter = idx + 1\n","          temp_hits+=1\n","\n","\n","          Cross_Encoder_hit_recall_list[idx]=1\n","\n","\n","          Cross_Encoder_tmp_map += temp_hits/(idx+1)\n","          tmep_answer.remove(c)\n","  Cross_Encoder_tmp_map /= len(answer)\n","  Cross_Encoder_tmp_mrr = 0.0\n","  if Cross_Encoder_counter!= -1:\n","    Cross_Encoder_tmp_mrr = 1/Cross_Encoder_counter\n","\n","\n","\n","  return BM25_counter,BM25_tmp_mrr,BM25_tmp_map,Bi_Encoder_counter,Bi_Encoder_tmp_mrr,Bi_Encoder_tmp_map,Cross_Encoder_counter,Cross_Encoder_tmp_mrr,Cross_Encoder_tmp_map,str(answer),Bi_Encoder_hit_list,Bi_Encoder_hit_recall_list,Cross_Encoder_hit_list,Cross_Encoder_hit_recall_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"soZ1nH4_I4Zi"},"source":["BM25_mrr = 0\n","BM25_map = 0\n","\n","Bi_Encoder_mrr = 0\n","Bi_Encoder_map = 0\n","\n","Cross_Encoder_mrr = 0\n","Cross_Encoder_map = 0\n","\n","api_list =[]\n","good_result=[]\n","\n","\n","Bi_Encoder_precision=[0]*4\n","Bi_Encoder_recall=[0]*4\n","\n","Cross_Encoder_precision=[0]*4\n","Cross_Encoder_recall=[0]*4\n","\n","for idx in range(len(queries)):\n","# for idx in range(10):\n","  \n","  BM25_counter,BM25_tmp_mrr,BM25_tmp_map,Bi_Encoder_counter,Bi_Encoder_tmp_mrr,Bi_Encoder_tmp_map,Cross_Encoder_counter,Cross_Encoder_tmp_mrr,Cross_Encoder_tmp_map,answer_api,Bi_Encoder_hit_list,Bi_Encoder_hit_recall_list,Cross_Encoder_hit_list,Cross_Encoder_hit_recall_list = evaluate(query = queries[idx], answer = queries_answers[idx])\n","  \n","  print(BM25_counter, Bi_Encoder_counter, Cross_Encoder_counter)\n","\n","  len_api = len(eval(answer_api))\n","  print()\n","  \n","  temp_precision=[0]*4\n","  temp_recall=[0]*4\n","  for idx, n in enumerate([1,3,5,10]):\n","    temp_precision[idx] = sum(Bi_Encoder_hit_list[:n])/n\n","    temp_recall[idx] = sum(Bi_Encoder_hit_recall_list[:n])/(len_api)\n","\n","  Bi_Encoder_precision = [x + y for (x, y) in zip(Bi_Encoder_precision, temp_precision)] \n","  Bi_Encoder_recall = [x + y for (x, y) in zip(Bi_Encoder_recall, temp_recall)] \n","\n","\n","  temp_precision=[0]*4\n","  temp_recall=[0]*4\n","  for idx, n in enumerate([1,3,5,10]):\n","    temp_precision[idx] = sum(Cross_Encoder_hit_list[:n])/n\n","    temp_recall[idx] = sum(Cross_Encoder_hit_recall_list[:n])/(len_api)\n","\n","  Cross_Encoder_precision = [x + y for (x, y) in zip(Cross_Encoder_precision, temp_precision)] \n","  Cross_Encoder_recall = [x + y for (x, y) in zip(Cross_Encoder_recall, temp_recall)] \n","\n","\n","  # print(BM25_tmp_mrr, Bi_Encoder_tmp_mrr, Cross_Encoder_tmp_mrr)\n","  # print(BM25_tmp_map, Bi_Encoder_tmp_map, Cross_Encoder_tmp_map)\n","  # if -1<Bi_Encoder_counter < 3 or -1<Cross_Encoder_counter < 3:\n","  #   good_result.append([queries[idx], queries_answers[idx]])\n","\n","  api_list.append(answer_api)\n","  BM25_mrr+=BM25_tmp_mrr\n","  BM25_map+=BM25_tmp_map\n","\n","  Bi_Encoder_mrr+=Bi_Encoder_tmp_mrr\n","  Bi_Encoder_map+=Bi_Encoder_tmp_map\n","  \n","  Cross_Encoder_mrr+=Cross_Encoder_tmp_mrr\n","  Cross_Encoder_map+=Cross_Encoder_tmp_map\n","\n","BM25_mrr/=len(queries)\n","BM25_map/=len(queries)\n","\n","Bi_Encoder_mrr/=len(queries)\n","Bi_Encoder_map/=len(queries)\n","\n","Cross_Encoder_mrr/=len(queries)\n","Cross_Encoder_map/=len(queries)\n","\n","Bi_Encoder_precision = [x/len(queries) for x in Bi_Encoder_precision]\n","Bi_Encoder_recall = [x/len(queries) for x in Bi_Encoder_recall]\n","\n","\n","Cross_Encoder_precision = [x/len(queries) for x in Cross_Encoder_precision]\n","Cross_Encoder_recall = [x/len(queries) for x in Cross_Encoder_recall]\n","\n","print(\"Bi_Encoder_precision\")\n","print(Bi_Encoder_precision)\n","\n","print(\"Bi_Encoder_recall\")\n","print(Bi_Encoder_recall)\n","\n","print(\"Cross_Encoder_precision\")\n","print(Cross_Encoder_precision)\n","\n","print(\"Cross_Encoder_recall\")\n","print(Cross_Encoder_recall)\n","\n","print(BM25_mrr,Bi_Encoder_mrr,Cross_Encoder_mrr)\n","print(BM25_map,Bi_Encoder_map,Cross_Encoder_map)\n","print(len(list(set(api_list))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jy6XpNsKjIE"},"source":["good_result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DteX35WDX_5y"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]}]}